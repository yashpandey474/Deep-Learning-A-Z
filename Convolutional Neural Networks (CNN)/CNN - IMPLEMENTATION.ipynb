{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c4c0db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "754ec797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dfdf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 1 - DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0976bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#APPLY TRANSFORMATIONS ON TRAINING SET TO AVOID OVERFITTING\n",
    "\n",
    "#-> GEOMETRICAL TRANSFORMATIONS; ZOOM IN, OUT; AUGMENT IMAGES\n",
    "#-> IMAGE AUGMENTATION [ON TRAINING SET]\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    #COMPULSARY FEATURE SCALING (0-1)\n",
    "                    rescale = 1./255, #FEATURE SCALING; DIVIDE EACH PIXEL VALUE BY 255\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range = 0.2,\n",
    "                    horizontal_flip = True\n",
    ")\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "                'dataset/training_set', #PATH TO FOLDER CONTAINING ALL IMAGES\n",
    "                target_size = (64,64),    #FINAL SIZE OF IMAGE WHEN FED TO CNN [HIGHER INCREASES COMPUTATIONAL TIME]\n",
    "                batch_size = 32,\n",
    "                class_mode = 'binary' #ONLY 2 OUTCOMES; ELSE 'categorical'\n",
    ")\n",
    "    \n",
    "                \n",
    "\n",
    "# ONLY SCALING ON THE TESTING SET [NO AUGMENTATION]\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "            'dataset/test_set',\n",
    "            target_size = (64,64),\n",
    "            batch_size = 32,\n",
    "            class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e2e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2 - BUILDING THE CNN\n",
    "\n",
    "\n",
    "#INITIALISING THE CNN\n",
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f86532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1 - CONVOLUTION\n",
    "cnn.add(Conv2D(\n",
    "    activation='relu', #RECTIFIER ACTIVATION FUNCTION\n",
    "    input_shape = (64,64, 3), #3 BECAUSE COLOURED (RGB) #ONLY IN 1ST LAYER\n",
    "    filters  = 32, #NUMBER OF FEATURES\n",
    "    kernel_size = 3 # 3X3 ARRAY\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4bdd5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2 - POOLING\n",
    "cnn.add(\n",
    "    MaxPool2D(\n",
    "    pool_size = 2, #2X2 ARRAY\n",
    "    strides=2 #SHIFT BY 2 PIXEL EACH TIME\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ee01e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECOND CONVOLUTIONAL LAYER\n",
    "cnn.add(Conv2D(\n",
    "    activation='relu', #RECTIFIER ACTIVATION FUNCTION\n",
    "    filters  = 32, #NUMBER OF FEATURES\n",
    "    kernel_size = 3 # 3X3 ARRAY\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a40d014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP - 3 - FLATTENING\n",
    "cnn.add(\n",
    "    Flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fd1b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP - 4 - FULLY CONNECTED LAYER\n",
    "cnn.add(\n",
    "    Dense(\n",
    "        units = 128,\n",
    "        activation = 'relu'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1c983af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP - 5 - OUTPUT LAYER [FULLY CONNECTED TO HIDDEN LAYER]\n",
    "cnn.add(\n",
    "    Dense(\n",
    "        units = 1, #BINARY CLASSIFICATION\n",
    "        activation = 'sigmoid' #FOR MULTI-CLASS: SOFTMAX\n",
    "    )\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29ac0899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART - 3: TRAINING THE CNN\n",
    "\n",
    "\n",
    "#COMPILING THE CNN MODEL\n",
    "cnn.compile(\n",
    "    optimizer = 'adam', #SGD OPTIMIZER\n",
    "    loss = 'binary_crossentropy', #BINARY CLASSIFICATION\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80f6017a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "  1/250 [..............................] - ETA: 44s - loss: 0.4780 - accuracy: 0.7812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-24 23:18:12.157699: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 49s 197ms/step - loss: 0.3854 - accuracy: 0.8236 - val_loss: 0.5028 - val_accuracy: 0.7790\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 52s 206ms/step - loss: 0.3679 - accuracy: 0.8351 - val_loss: 0.5217 - val_accuracy: 0.7730\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 45s 182ms/step - loss: 0.3506 - accuracy: 0.8401 - val_loss: 0.5220 - val_accuracy: 0.7720\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 44s 175ms/step - loss: 0.3480 - accuracy: 0.8428 - val_loss: 0.5740 - val_accuracy: 0.7345\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 40s 162ms/step - loss: 0.3384 - accuracy: 0.8511 - val_loss: 0.5178 - val_accuracy: 0.7825\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 40s 161ms/step - loss: 0.3352 - accuracy: 0.8549 - val_loss: 0.5233 - val_accuracy: 0.7885\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 41s 164ms/step - loss: 0.3094 - accuracy: 0.8636 - val_loss: 0.5232 - val_accuracy: 0.7770\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 44s 175ms/step - loss: 0.3058 - accuracy: 0.8666 - val_loss: 0.5557 - val_accuracy: 0.7730\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 45s 178ms/step - loss: 0.2909 - accuracy: 0.8748 - val_loss: 0.5535 - val_accuracy: 0.7855\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.2778 - accuracy: 0.8804 - val_loss: 0.5671 - val_accuracy: 0.7795\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 40s 161ms/step - loss: 0.2780 - accuracy: 0.8813 - val_loss: 0.5519 - val_accuracy: 0.7815\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.2543 - accuracy: 0.8926 - val_loss: 0.5871 - val_accuracy: 0.7880\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 43s 173ms/step - loss: 0.2465 - accuracy: 0.8988 - val_loss: 0.5922 - val_accuracy: 0.7990\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 45s 182ms/step - loss: 0.2379 - accuracy: 0.8984 - val_loss: 0.6206 - val_accuracy: 0.7715\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.2314 - accuracy: 0.9031 - val_loss: 0.5932 - val_accuracy: 0.7815\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 47s 187ms/step - loss: 0.2304 - accuracy: 0.9022 - val_loss: 0.6456 - val_accuracy: 0.7875\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 46s 185ms/step - loss: 0.2129 - accuracy: 0.9146 - val_loss: 0.6688 - val_accuracy: 0.7680\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.2159 - accuracy: 0.9125 - val_loss: 0.6036 - val_accuracy: 0.7970\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 57s 227ms/step - loss: 0.1921 - accuracy: 0.9210 - val_loss: 0.6901 - val_accuracy: 0.7900\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 56s 225ms/step - loss: 0.1928 - accuracy: 0.9220 - val_loss: 0.6805 - val_accuracy: 0.7905\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 53s 213ms/step - loss: 0.1847 - accuracy: 0.9250 - val_loss: 0.6584 - val_accuracy: 0.7900\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 54s 216ms/step - loss: 0.1851 - accuracy: 0.9274 - val_loss: 0.7570 - val_accuracy: 0.7915\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 53s 210ms/step - loss: 0.1754 - accuracy: 0.9305 - val_loss: 0.6586 - val_accuracy: 0.7955\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 54s 214ms/step - loss: 0.1723 - accuracy: 0.9310 - val_loss: 0.7130 - val_accuracy: 0.7800\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 53s 212ms/step - loss: 0.1620 - accuracy: 0.9355 - val_loss: 0.6777 - val_accuracy: 0.7855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb03e142ef0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAINING THE CNN MODEL ON TRAINING_SET\n",
    "cnn.fit(\n",
    "    x=training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs = 25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "019ba87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "# MAKING A SINGLE PREDICTION\n",
    "\n",
    "#LOAD INPUT IMAGE: PIL FORMAT: INPUT SHAPE IS IMPORTANT\n",
    "test_image = image.load_img(\n",
    "        \"dataset/single_prediction/download-4.jpg\", \n",
    "        target_size = (64, 64)\n",
    "    ) \n",
    "\n",
    "#PIL TO NUMPY ARRAY\n",
    "test_image = image.img_to_array(\n",
    "    test_image\n",
    ")\n",
    "\n",
    "#CONVERT IMAGE TO A BATCH (AS BATCH_SIZE > 1 IN TRAINING & TESTING SET)\n",
    "test_image = np.expand_dims(\n",
    "    test_image,\n",
    "    axis = 0 #DIMENSION OF BATCH WILL BE THE FIRST DIMENSION\n",
    ")\n",
    "\n",
    "#PREDICTION [PROBABILITY]\n",
    "result = cnn.predict(\n",
    "    test_image/255.0\n",
    ")\n",
    "\n",
    "#CLASS CORRESPONDING TO 0 & TO 1\n",
    "training_set.class_indices\n",
    "\n",
    "\n",
    "if result[0][0] > 0.5:   # 0-> BATCH 0 -> 1ST & ONLY PREDICTION\n",
    "    prediction = 'dog'\n",
    "    \n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db95f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
